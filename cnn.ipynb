{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "# sklearn Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Keras\n",
    "import keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data by 80% in training and 20% in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 306 files [00:10, 29.37 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "# To only split into training and validation set, set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio('./img_data/', output=\"./data\", seed=1337, ratio=(.8, .2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1488 images belonging to 7 classes.\n",
      "Found 407 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True) \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set = train_datagen.flow_from_directory('./data/train',target_size=(64, 64),batch_size=32,class_mode='categorical',shuffle = False)\n",
    "test_set = test_datagen.flow_from_directory('./data/val',target_size=(64, 64),batch_size=32,class_mode='categorical',shuffle = False )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Convolutional Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 31, 31, 32)        896       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 93,703\n",
      "Trainable params: 93,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "input_shape=(64, 64, 3)#1st hidden layer\n",
    "model.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))#2nd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))#3rd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(AveragePooling2D((2, 2), strides=(2,2)))\n",
    "model.add(Activation('relu'))#Flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))#Add fully connected layer.\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))#Output layer\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 31, 31, 32)        896       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 93,703\n",
      "Trainable params: 93,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 8\n",
    "learning_rate = 0.01\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.9\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 47/100 [=============>................] - ETA: 2:14 - loss: 1.8987 - accuracy: 0.37 - ETA: 2:41 - loss: 1.9103 - accuracy: 0.32 - ETA: 3:06 - loss: 1.9108 - accuracy: 0.30 - ETA: 3:08 - loss: 1.9172 - accuracy: 0.27 - ETA: 2:48 - loss: 1.9238 - accuracy: 0.25 - ETA: 2:17 - loss: 1.9273 - accuracy: 0.24 - ETA: 1:56 - loss: 1.9299 - accuracy: 0.23 - ETA: 1:56 - loss: 1.9304 - accuracy: 0.22 - ETA: 1:43 - loss: 1.9291 - accuracy: 0.22 - ETA: 1:36 - loss: 1.9277 - accuracy: 0.22 - ETA: 1:36 - loss: 1.9272 - accuracy: 0.22 - ETA: 1:37 - loss: 1.9257 - accuracy: 0.22 - ETA: 1:36 - loss: 1.9243 - accuracy: 0.22 - ETA: 1:29 - loss: 1.9222 - accuracy: 0.22 - ETA: 1:30 - loss: 1.9208 - accuracy: 0.22 - ETA: 1:30 - loss: 1.9193 - accuracy: 0.22 - ETA: 1:30 - loss: 1.9177 - accuracy: 0.22 - ETA: 1:25 - loss: 1.9157 - accuracy: 0.22 - ETA: 1:20 - loss: 1.9143 - accuracy: 0.22 - ETA: 1:18 - loss: 1.9146 - accuracy: 0.22 - ETA: 1:19 - loss: 1.9150 - accuracy: 0.22 - ETA: 1:18 - loss: 1.9149 - accuracy: 0.22 - ETA: 1:18 - loss: 1.9149 - accuracy: 0.22 - ETA: 1:18 - loss: 1.9147 - accuracy: 0.22 - ETA: 1:17 - loss: 1.9143 - accuracy: 0.22 - ETA: 1:17 - loss: 1.9136 - accuracy: 0.22 - ETA: 1:17 - loss: 1.9130 - accuracy: 0.22 - ETA: 1:15 - loss: 1.9122 - accuracy: 0.22 - ETA: 1:13 - loss: 1.9115 - accuracy: 0.22 - ETA: 1:12 - loss: 1.9107 - accuracy: 0.22 - ETA: 1:11 - loss: 1.9099 - accuracy: 0.22 - ETA: 1:11 - loss: 1.9091 - accuracy: 0.22 - ETA: 1:10 - loss: 1.9081 - accuracy: 0.22 - ETA: 1:08 - loss: 1.9074 - accuracy: 0.22 - ETA: 1:06 - loss: 1.9071 - accuracy: 0.22 - ETA: 1:05 - loss: 1.9066 - accuracy: 0.22 - ETA: 1:04 - loss: 1.9061 - accuracy: 0.22 - ETA: 1:03 - loss: 1.9058 - accuracy: 0.22 - ETA: 1:01 - loss: 1.9055 - accuracy: 0.22 - ETA: 59s - loss: 1.9052 - accuracy: 0.2266 - ETA: 59s - loss: 1.9049 - accuracy: 0.226 - ETA: 58s - loss: 1.9046 - accuracy: 0.226 - ETA: 57s - loss: 1.9044 - accuracy: 0.225 - ETA: 57s - loss: 1.9043 - accuracy: 0.225 - ETA: 56s - loss: 1.9043 - accuracy: 0.225 - ETA: 55s - loss: 1.9043 - accuracy: 0.224 - ETA: 55s - loss: 1.9042 - accuracy: 0.2246WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 5000 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 200 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 64s 636ms/step - loss: 1.9012 - accuracy: 0.2210 - val_loss: 1.8138 - val_accuracy: 0.2629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2f7114f65c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_set,steps_per_epoch=100,epochs=50,validation_data=test_set,validation_steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "Loss=  1.8137733936309814 Accuracy= 26.2899249792099\n"
     ]
    }
   ],
   "source": [
    "y=model.evaluate_generator(generator=test_set, steps=50)\n",
    "y[1]=y[1]*100\n",
    "print(\"Loss= \", y[0], 'Accuracy=' ,y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
